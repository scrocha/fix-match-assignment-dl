{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea5228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.transforms import RandAugment\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple, Callable\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "659f9ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES: int = 10\n",
    "BATCH_SIZE: int = 64\n",
    "TOTAL_EPOCHS: int = 100\n",
    "LR: float = 0.03\n",
    "MOMENTUM: float = 0.9\n",
    "WEIGHT_DECAY: float = 5e-4\n",
    "\n",
    "LAMBDA_U: float = 1.0\n",
    "T: float = 0.95\n",
    "\n",
    "SEED: int = 42\n",
    "DATA_DIR: str = './data'\n",
    "SAVE_DIR: str = './experiments'\n",
    "SAVE_N_EPOCHS: int = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ef52a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoCropsTransform:\n",
    "    def __init__(self, weak_transform: Callable, strong_transform: Callable):\n",
    "        self.weak_transform = weak_transform\n",
    "        self.strong_transform = strong_transform\n",
    "\n",
    "    def __call__(self, x: Image.Image) -> List[torch.Tensor]:\n",
    "        return [self.weak_transform(x), self.strong_transform(x)]\n",
    "\n",
    "\n",
    "class CIFAR10SemiSupervised(Dataset):\n",
    "    def __init__(self, base_dataset: Dataset, transform: Callable):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
    "        img, label = self.base_dataset[idx]\n",
    "        return self.transform(img), label\n",
    "\n",
    "\n",
    "def get_dataloaders(num_labeled_per_class: int):\n",
    "    cifar10_mean = (0.4914, 0.4822, 0.4465)\n",
    "    cifar10_std = (0.2471, 0.2435, 0.2616)\n",
    "\n",
    "    base_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(cifar10_mean, cifar10_std),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    weak_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
    "            base_transform,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    strong_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
    "            RandAugment(num_ops=2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.RandomErasing(\n",
    "                p=1.0, scale=(0.25, 0.25), ratio=(1.0, 1.0), value=0\n",
    "            ),\n",
    "            transforms.Normalize(cifar10_mean, cifar10_std),\n",
    "        ]\n",
    "    )\n",
    "    test_transform = base_transform\n",
    "\n",
    "    train_data = datasets.CIFAR10(\n",
    "        DATA_DIR, train=True, download=True, transform=None\n",
    "    )\n",
    "    test_data = datasets.CIFAR10(\n",
    "        DATA_DIR, train=False, download=True, transform=test_transform\n",
    "    )\n",
    "\n",
    "    targets = np.array(train_data.targets)\n",
    "    labeled_indices = []\n",
    "    unlabeled_indices = []\n",
    "\n",
    "    for i in range(NUM_CLASSES):\n",
    "        indices = np.where(targets == i)[0]\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        labeled_indices.extend(indices[:num_labeled_per_class])\n",
    "        unlabeled_indices.extend(indices[num_labeled_per_class:])\n",
    "\n",
    "    random.shuffle(labeled_indices)\n",
    "    random.shuffle(unlabeled_indices)\n",
    "\n",
    "    print(f\"Total de amostras: {len(targets)}\")\n",
    "    print(f\"Amostras rotuladas: {len(labeled_indices)}\")\n",
    "    print(f\"Amostras não rotuladas: {len(unlabeled_indices)}\")\n",
    "\n",
    "    labeled_dataset = CIFAR10SemiSupervised(\n",
    "        Subset(train_data, labeled_indices), transform=weak_transform\n",
    "    )\n",
    "\n",
    "    unlabeled_dataset = CIFAR10SemiSupervised(\n",
    "        Subset(train_data, unlabeled_indices),\n",
    "        transform=TwoCropsTransform(weak_transform, strong_transform),\n",
    "    )\n",
    "\n",
    "    labeled_batch_size = min(BATCH_SIZE, len(labeled_indices))\n",
    "    if labeled_batch_size == 0:\n",
    "        labeled_batch_size = 1\n",
    "\n",
    "    labeled_loader = DataLoader(\n",
    "        labeled_dataset,\n",
    "        batch_size=labeled_batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=2,\n",
    "    )\n",
    "\n",
    "    unlabeled_loader = DataLoader(\n",
    "        unlabeled_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=2,\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_data, batch_size=100, shuffle=False, num_workers=2\n",
    "    )\n",
    "\n",
    "    return labeled_loader, unlabeled_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4be90943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet18_for_cifar(num_classes: int = NUM_CLASSES) -> nn.Module:\n",
    "    model = models.resnet18(weights=None, num_classes=num_classes)\n",
    "\n",
    "    model.conv1 = nn.Conv2d(\n",
    "        3, 64, kernel_size=3, stride=1, padding=1, bias=False\n",
    "    )\n",
    "    model.maxpool = nn.Identity()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def fixmatch_loss(\n",
    "    logits_x: torch.Tensor,\n",
    "    targets_x: torch.Tensor,\n",
    "    logits_u_w: torch.Tensor,\n",
    "    logits_u_s: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "\n",
    "    loss_x = nn.CrossEntropyLoss()(logits_x, targets_x)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        probs_u_w = torch.softmax(logits_u_w, dim=1)\n",
    "        max_probs, pseudo_label = torch.max(probs_u_w, dim=1)\n",
    "\n",
    "        mask = (max_probs >= T).float()\n",
    "\n",
    "    loss_u_all = nn.CrossEntropyLoss(reduction='none')(\n",
    "        logits_u_s, pseudo_label\n",
    "    )\n",
    "    loss_u = (loss_u_all * mask).mean()\n",
    "\n",
    "    return loss_x, LAMBDA_U * loss_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1546636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    labeled_loader: DataLoader,\n",
    "    unlabeled_loader: DataLoader,\n",
    "    optimizer: optim.Optimizer,\n",
    "    device: torch.device,\n",
    ") -> Tuple[float, float, float]:\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_loss_x = 0\n",
    "    total_loss_u = 0\n",
    "\n",
    "    labeled_iter = iter(labeled_loader)\n",
    "    num_batches = len(unlabeled_loader)\n",
    "\n",
    "    for i, (batch_unlabeled) in enumerate(unlabeled_loader):\n",
    "\n",
    "        try:\n",
    "            (x_batch, targets_x_batch) = next(labeled_iter)\n",
    "        except StopIteration:\n",
    "            labeled_iter = iter(labeled_loader)\n",
    "            (x_batch, targets_x_batch) = next(labeled_iter)\n",
    "\n",
    "        x_batch = x_batch.to(device)\n",
    "        targets_x_batch = targets_x_batch.to(device)\n",
    "\n",
    "        u_w_batch = batch_unlabeled[0][0].to(device)\n",
    "        u_s_batch = batch_unlabeled[0][1].to(device)\n",
    "\n",
    "        inputs = torch.cat((x_batch, u_w_batch, u_s_batch))\n",
    "        logits = model(inputs)\n",
    "\n",
    "        logits_x = logits[: x_batch.size(0)]\n",
    "        logits_u_w, logits_u_s = logits[x_batch.size(0) :].chunk(2)\n",
    "\n",
    "        loss_x, loss_u = fixmatch_loss(\n",
    "            logits_x, targets_x_batch, logits_u_w, logits_u_s\n",
    "        )\n",
    "        loss = loss_x + loss_u\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_loss_x += loss_x.item()\n",
    "        total_loss_u += loss_u.item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    avg_loss_x = total_loss_x / num_batches\n",
    "    avg_loss_u = total_loss_u / num_batches\n",
    "\n",
    "    return avg_loss, avg_loss_x, avg_loss_u\n",
    "\n",
    "\n",
    "def validate_model(\n",
    "    model: nn.Module, test_loader: DataLoader, device: torch.device\n",
    ") -> float:\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e58ee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def train_model_with_fixmatch(num_labeled_per_class: int) -> float:\n",
    "    set_seed(SEED)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    experiment_name = f\"FixMatch_{num_labeled_per_class}_labels_per_class\"\n",
    "    print(f\"Iniciando: {experiment_name}\")\n",
    "    print(f\"Usando device: {device}\")\n",
    "\n",
    "    labeled_loader, unlabeled_loader, test_loader = get_dataloaders(\n",
    "        num_labeled_per_class\n",
    "    )\n",
    "\n",
    "    model = get_resnet18_for_cifar(NUM_CLASSES).to(device)\n",
    "\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=LR,\n",
    "        momentum=MOMENTUM,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        nesterov=True,\n",
    "    )\n",
    "\n",
    "    best_acc = 0.0\n",
    "\n",
    "    exp_dir = os.path.join(SAVE_DIR, experiment_name)\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "    for epoch in tqdm(range(1, TOTAL_EPOCHS + 1)):\n",
    "\n",
    "        train_loss, train_loss_x, train_loss_u = train_one_epoch(\n",
    "            model, labeled_loader, unlabeled_loader, optimizer, device\n",
    "        )\n",
    "\n",
    "        test_acc = validate_model(model, test_loader, device)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch:03d}/{TOTAL_EPOCHS:03d} | \"\n",
    "            f\"Loss: {train_loss:.4f} (Lx: {train_loss_x:.4f}, Lu: {train_loss_u:.4f}) | \"\n",
    "            f\"Test Acc: {test_acc:.2f}%\"\n",
    "        )\n",
    "\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                os.path.join(exp_dir, 'best_model.pth'),\n",
    "            )\n",
    "            print(\n",
    "                f\"\\tModelo Salvo com acc: {best_acc:.2f}%\"\n",
    "            )\n",
    "\n",
    "        if epoch % SAVE_N_EPOCHS == 0:\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                os.path.join(exp_dir, f'model_epoch_{epoch}.pth'),\n",
    "            )\n",
    "\n",
    "    print(\n",
    "        f\"Treinamento de {experiment_name} concluído. \"\n",
    "        f\"Melhor Acurácia: {best_acc:.2f}%\"\n",
    "    )\n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "449ce5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d379bde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    labeled_per_class_cases = [\n",
    "        1,  # Caso 1: 10 rótulos total\n",
    "        4,  # Caso 2: 40 rótulos total\n",
    "        25,  # Caso 3: 250 rótulos total\n",
    "        400,  # Caso 4: 4.000 rótulos total\n",
    "    ]\n",
    "\n",
    "    labeled_per_class_cases.append(100)\n",
    "\n",
    "    labeled_per_class_cases.sort()\n",
    "\n",
    "    results = dict()\n",
    "\n",
    "    for num_labeled in labeled_per_class_cases:\n",
    "        acc = train_model_with_fixmatch(num_labeled)\n",
    "        results[f\"{num_labeled} rótulos/classe\"] = acc\n",
    "\n",
    "    print()\n",
    "    print(\"#\" * 50)\n",
    "    print()\n",
    "    print(\"Resultados:\")\n",
    "    for case, acc in results.items():\n",
    "        print(f\"Caso {case}: Melhor Acurácia de Teste: {acc:.2f}%\")\n",
    "    print()\n",
    "    print(\"#\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf797b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando: FixMatch_1_labels_per_class\n",
      "Usando device: cuda\n",
      "Total de amostras: 50000\n",
      "Amostras rotuladas: 10\n",
      "Amostras não rotuladas: 49990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fix-match-assignment-dl (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
